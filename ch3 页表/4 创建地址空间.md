## 7. 进程页表

大多数用于操作地址空间和页表的xv6代码都写在 **_vm.c_** ([kernel/vm.c:1](https://github.com/mit-pdos/xv6-riscv/blob/riscv//kernel/vm.c#L1)) 中。其核心数据结构是`pagetable_t`，它实际上是指向RISC-V根页表页的指针；一个`pagetable_t`可以是内核页表，也可以是一个进程页表。

我们先详细了解内核中的pagetable_t和pte_t的底层：

它们简单到难以置信，在`riscv.h`中，它们的定义如下：

```c
typedef uint64 pte_t;

typedef uint64 *pagetable_t; // 512 PTEs
```

`pagetable_t`是一个8字节的指针，以此来表示具有512个条目的页表，定义为指针，允许了内核进行数组操作。pte_t是一个8字节条目，其各位含义已在第二节中阐述过。之所以没有使用复杂数据结构，是因为页表本身只是包含了512个条目的数组。

### a. walk函数的实现：

```c
// Return the address of the PTE in page table pagetable

// that corresponds to virtual address va.  If alloc!=0,

// create any required page-table pages.

//

// The risc-v Sv39 scheme has three levels of page-table

// pages. A page-table page contains 512 64-bit PTEs.

// A 64-bit virtual address is split into five fields:

//   39..63 -- must be zero.

//   30..38 -- 9 bits of level-2 index.

//   21..29 -- 9 bits of level-1 index.

//   12..20 -- 9 bits of level-0 index.

//    0..11 -- 12 bits of byte offset within the page.

pte_t *

walk(pagetable_t pagetable, uint64 va, int alloc)

{
  // 如果地址超出空间
  if(va >= MAXVA)

    panic("walk");

  for(int level = 2; level > 0; level--) {

    pte_t *pte = &pagetable[PX(level, va)];

    if(*pte & PTE_V) {

      pagetable = (pagetable_t)PTE2PA(*pte);

    } else {

      if(!alloc || (pagetable = (pde_t*)kalloc()) == 0)

        return 0;

      memset(pagetable, 0, PGSIZE);

      *pte = PA2PTE(pagetable) | PTE_V;

    }

  }

  return &pagetable[PX(0, va)];

}
```

以下是逐行详细解析：

---

#### 函数头：输入与输出


```c
pte_t *
walk(pagetable_t pagetable, uint64 va, int alloc)
```

- **`pagetable_t pagetable`**：根页表（L2）的内核虚拟地址。
    
- **`uint64 va`**：需要查找的 39 位虚拟地址。
    
- **`int alloc`**：布尔值。如果路径上的中间级页表不存在，是否申请新的物理页来创建它们。
    
- **返回值 (`pte_t *`)**：返回最后一级页表（L0）中对应 `va` 的那个 PTE 的**内核虚拟地址**。
    

---

#### 第一部分：安全检查


```c
  if(va >= MAXVA)
    panic("walk");
```

- **解析**：Sv39 架构只使用 39 位地址，因此虚拟地址不能超过 $2^{39}-1$（即 `MAXVA`）。如果超过了，说明传入了非法地址，内核直接崩溃报错。
    

---

#### 第二部分：三级页表的“漫游”循环


```c
  for(int level = 2; level > 0; level--) {
    pte_t *pte = &pagetable[PX(level, va)];
```

- **`for` 循环**：从第 2 级（根）开始，向下寻找直到第 1 级。注意循环不处理第 0 级，因为第 0 级是最终目的地。
    
- **`PX(level, va)`**：这是一个位运算宏。它会根据当前的 `level`（2, 1 或 0），从 39 位 `va` 中提取出对应的 9 位索引（Index）。
    
- **`&pagetable[PX(...)]`**：在当前页表页（512 个条目）中，根据索引找到对应的那个 PTE 的地址。
    

---

#### 第三部分：处理中间级页表是否存在


```c
    if(*pte & PTE_V) {
      pagetable = (pagetable_t)PTE2PA(*pte);
    } 
```

- **`if(*pte & PTE_V)`**：检查这个 PTE 的“有效位”（Valid bit）。
    
- **`PTE2PA(*pte)`**：如果有效，说明下一级页表已经存在。利用 `PTE2PA` 宏从 PTE 中提取出下一级页表的**物理地址**，并将其强转为指针，准备下一轮循环。
    

---

#### 第四部分：按需分配页表（关键）


```c
    else {
      if(!alloc || (pagetable = (pde_t*)kalloc()) == 0)
        return 0;
      memset(pagetable, 0, PGSIZE);
      *pte = PA2PTE(pagetable) | PTE_V;
    }
```

- **`if(!alloc ...)`**：如果中间级页表不存在且 `alloc` 为 0，或者内存耗尽（`kalloc` 返回 0），则查找失败，返回空指针。
    
- **`kalloc()`**：申请一个 4096 字节的物理页作为新的下一级页表。
    
- **`memset(..., 0, PGSIZE)`**：清空新页表。这非常重要，确保所有新 PTE 初始状态都是无效的（`PTE_V` 为 0）。
    
- **`*pte = PA2PTE(pagetable) | PTE_V`**：将新页表的物理地址填入当前级的 PTE 中，并标记为有效。
    

---

#### 第五部分：返回结果


```c
  return &pagetable[PX(0, va)];
```

- **解析**：循环结束后，`pagetable` 现在指向的是最后一级（第 0 级）页表的起始地址。
    
- **逻辑**：最后一次使用 `PX(0, va)` 算出索引，返回指向该 PTE 的指针。

### b. mappages的实现

```c
// Create PTEs for virtual addresses starting at va that refer to

// physical addresses starting at pa. va and size might not

// be page-aligned. Returns 0 on success, -1 if walk() couldn't

// allocate a needed page-table page.

int

mappages(pagetable_t pagetable, uint64 va, uint64 size, uint64 pa, int perm)

{

  uint64 a, last;

  pte_t *pte;

  

  a = PGROUNDDOWN(va);

  last = PGROUNDDOWN(va + size - 1);

  for(;;){

    if((pte = walk(pagetable, a, 1)) == 0)

      return -1;

    if(*pte & PTE_V)

      panic("remap");

    *pte = PA2PTE(pa) | perm | PTE_V;

    if(a == last)

      break;

    a += PGSIZE;

    pa += PGSIZE;

  }

  return 0;

}
```

下面是逐行解析：

它的核心任务是：**在页表中建立一段连续虚拟地址到一段物理地址的映射关系。**

简单来说，如果你申请了一块内存，`mappages` 负责在“字典”（页表）里写下：“虚拟地址 A 对应物理地址 B，权限是 C”。

---

#### 1. 处理地址对齐


```c
  a = PGROUNDDOWN(va);
  last = PGROUNDDOWN(va + size - 1);
```

- **`a` (起点)**：使用你刚才问到的 `PGROUNDDOWN`。即使传入的 `va` 是页中间（如 `0x1050`），映射也必须从页的开头（`0x1000`）开始，因为页表条目（PTE）只能映射整个页。
    
- **`last` (终点)**：计算这段空间的最后一个字节所在的页开头。
    
    - **技巧**：`va + size - 1` 是这段空间的最后一个字节。对其取 `PGROUNDDOWN` 确保了循环能够覆盖到最后一页。
        

---

#### 2. 映射循环的核心逻辑


```c
  for(;;){
    if((pte = walk(pagetable, a, 1)) == 0)
      return -1;
```

- **调用 `walk`**：这是你在上一环节深入研究的函数。
    
- **`1` (alloc)**：这里传入 1，意味着如果路径上的二级或一级页表还没建立，`walk` 会自动调用 `kalloc` 申请新页来补全页表树。
    
- **错误处理**：如果 `walk` 返回 0，说明物理内存耗尽，无法创建页表，函数返回 -1。
    

---

#### 3. 防止重复映射 (Panic)


```c
    if(*pte & PTE_V)
      panic("remap");
```

- **含义**：如果 `walk` 返回的这个 PTE 已经设置了有效位（`PTE_V`），说明这个虚拟地址**已经映射过了**。
    
- **安全性**：内核不允许在没有明确“解除映射”（unmap）的情况下覆盖原有的映射，否则可能导致内存泄漏或严重的逻辑错误。
    

---

#### 4. 写入映射条目

```c
    *pte = PA2PTE(pa) | perm | PTE_V;
```

- **`PA2PTE(pa)`**：将物理地址转换成 PTE 要求的格式（去掉低 12 位，移到正确的位置）。
    
- **`perm | PTE_V`**：叠加权限位（如 `PTE_W` 可写、`PTE_R` 可读）和有效位。
    
- **赋值**：这行代码通过存储指令，正式修改了物理内存中的页表内容。
    

---

#### 5. 指针步进

```c
    if(a == last)
      break;
    a += PGSIZE;
    pa += PGSIZE;
```

- **同步移动**：虚拟地址 `a` 指向下一页，物理地址 `pa` 也同步指向下一个 4096 字节的块。
    
- **退出条件**：当处理完 `last` 所在的页后，循环结束。


## 8. 页表创建过程

在`vm.c`中，名称以`kvm`开头的函数操作内核页表；以`uvm`开头的函数操作用户页表；其他函数用于二者。`copyout`和`copyin`复制数据到用户虚拟地址或从用户虚拟地址复制数据，这些虚拟地址作为系统调用参数提供; 由于它们需要显式地翻译这些地址，以便找到相应的物理内存，故将它们写在`vm.c`中。

在启动序列的前期，`main` 调用 `kvminit` (**_kernel/vm.c_**:54) 以使用 `kvmmake` (**_kernel/vm.c_**:20) 创建内核的页表。

`kvmmake`主要是一系列内存映射语句，此调用发生在 xv6 启用 RISC-V 上的分页之前，因此地址直接引用物理内存。`kvmmake` 首先分配一个物理内存页来保存根页表页。然后它调用`kvmmap`来装载内核需要的转换。转换包括内核的指令和数据、物理内存的上限到 `PHYSTOP`，并包括实际上是设备的内存。

```c
pagetable_t

kvmmake(void)

{

  pagetable_t kpgtbl;

  

  kpgtbl = (pagetable_t) kalloc();

  memset(kpgtbl, 0, PGSIZE);

  

  // uart registers

  kvmmap(kpgtbl, UART0, UART0, PGSIZE, PTE_R | PTE_W);

  // virtio mmio disk interface

  kvmmap(kpgtbl, VIRTIO0, VIRTIO0, PGSIZE, PTE_R | PTE_W);

  // PLIC

  kvmmap(kpgtbl, PLIC, PLIC, 0x4000000, PTE_R | PTE_W);


  // map kernel text executable and read-only.

  kvmmap(kpgtbl, KERNBASE, KERNBASE, (uint64)etext-KERNBASE, PTE_R | PTE_X);

  // map kernel data and the physical RAM we'll make use of.
  kvmmap(kpgtbl, (uint64)etext, (uint64)etext, PHYSTOP-(uint64)etext, PTE_R | PTE_W);
  
  // map the trampoline for trap entry/exit to
  
  // the highest virtual address in the kernel.
  kvmmap(kpgtbl, TRAMPOLINE, (uint64)trampoline, PGSIZE, PTE_R | PTE_X);

  // allocate and map a kernel stack for each process.

  proc_mapstacks(kpgtbl);

  return kpgtbl;

}
```

最后的`proc_mapstacks`为所有可能的进程分配内核栈，简单来说，内核栈（Kernel Stack）是进程进入“内核态”后的临时办公室。当程序（用户态）因为系统调用（如 `read`, `fork`）、中断或异常而陷入内核时，它不能再使用原来的用户态栈。原因很简单：**安全**与**隔离**。如果内核在用户提供的栈上运行，恶意程序可以通过修改栈指针来破坏内核的逻辑。

分配内核栈的函数实现如下：

```c
// Allocate a page for each process's kernel stack.

// Map it high in memory, followed by an invalid

// guard page.

void

proc_mapstacks(pagetable_t kpgtbl)

{

  struct proc *p;

  for(p = proc; p < &proc[NPROC]; p++) {

    char *pa = kalloc();

    if(pa == 0)

      panic("kalloc");

    uint64 va = KSTACK((int) (p - proc));

    kvmmap(kpgtbl, va, (uint64)pa, PGSIZE, PTE_R | PTE_W);

  }

}
```

在每两个内核栈中间存在保护页，这样，当进程的内核栈溢出时，内核就能捕捉到错误（访问不可访问的内存），从而提前阻断，防止其侵入其他进程的内核栈。内核栈被映射在高位，而不是恒等映射，这样既享受到了guard page带来的保护，又防止物理内存出现不可用的空洞（即guard page，上文已经叙述过）。

`kvmmap`(**_kernel/vm.c_**:127)调用`mappages`(**_kernel/vm.c_**:138)，`mappages`将范围虚拟地址到同等范围物理地址的映射装载到一个页表中。它以页面大小为间隔，为范围内的每个虚拟地址单独执行此操作。对于要映射的每个虚拟地址，`mappages`调用`walk`来查找该地址的PTE地址。然后，它初始化PTE以保存相关的物理页号、所需权限（`PTE_W`、`PTE_X`和/或`PTE_R`）以及用于标记PTE有效的`PTE_V`(**_kernel/vm.c_**:153)。

`main`调用`kvminithart` (**_kernel/vm.c_**:53)来安装内核页表。它将根页表页的物理地址写入寄存器`satp`。之后，CPU将使用内核页表转换地址。由于内核使用标识映射，下一条指令的当前虚拟地址将映射到正确的物理内存地址。

每个RISC-V CPU都将页表条目缓存在转译后备缓冲器（快表/TLB）中，当xv6更改页表时，它必须告诉CPU使相应的缓存TLB条目无效。如果没有这么做，那么在某个时候TLB可能会使用旧的缓存映射，指向一个在此期间已分配给另一个进程的物理页面，这样会导致一个进程可能能够在其他进程的内存上涂鸦。RISC-V有一个指令`sfence.vma`，用于刷新当前CPU的TLB。xv6在重新加载`satp`寄存器后，在`kvminithart`中执行`sfence.vma`，并在返回用户空间之前在用于切换至一个用户页表的`trampoline`代码中执行`sfence.vma` (**_kernel/trampoline.S_**:79)。